{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize SentenceTransformer model\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Load additional dictionary definitions from Excel file\n",
    "additional_dict_path = 'QanonMeaning.xlsx'\n",
    "additional_dict_df = pd.read_excel(additional_dict_path)\n",
    "additional_dict = dict(zip(additional_dict_df['word'].astype(str), additional_dict_df['meaning'].astype(str)))\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embeddings for the text using SentenceTransformer\"\"\"\n",
    "    return sbert_model.encode([text])[0]\n",
    "\n",
    "def get_sense_embeddings(word):\n",
    "    sense_embeddings = {}\n",
    "\n",
    "    # Check if the word is in the additional dictionary\n",
    "    if word in additional_dict:\n",
    "        additional_definition = additional_dict[word]\n",
    "        additional_embedding = get_embedding(additional_definition)\n",
    "        sense_embeddings[additional_definition] = additional_embedding\n",
    "\n",
    "    # Get definitions from the dictionary API if not found in the additional dictionary\n",
    "    url = f\"https://api.dictionaryapi.dev/api/v2/entries/en/{word}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for meaning in data[0]['meanings']:\n",
    "            for definition in meaning['definitions']:\n",
    "                sense_text = definition['definition']\n",
    "                sense_embedding = get_embedding(sense_text)\n",
    "                sense_embeddings[sense_text] = sense_embedding\n",
    "    \n",
    "    return sense_embeddings\n",
    "\n",
    "def disambiguate_word(sentence, target_word_regex, additional_words_meanings):\n",
    "    # Process the sentence using spaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Find the target words\n",
    "    target_words = [token.text for token in doc if re.match(target_word_regex, token.text, re.IGNORECASE)]\n",
    "    \n",
    "    if not target_words:\n",
    "        return None, None\n",
    "    \n",
    "    best_senses = {}\n",
    "    best_similarities = {}\n",
    "\n",
    "    # Include additional words meanings in the context\n",
    "    context_embeddings = [get_embedding(sentence)]\n",
    "    for meaning in additional_words_meanings.values():\n",
    "        context_embeddings.append(get_embedding(meaning))\n",
    "    context_embedding = sum(context_embeddings) / len(context_embeddings)\n",
    "    \n",
    "    for word in target_words:\n",
    "        # Get embeddings for each sense of the word\n",
    "        sense_embeddings = get_sense_embeddings(word)\n",
    "        \n",
    "        # Calculate cosine similarity between context embedding and each sense embedding\n",
    "        max_similarity = -1\n",
    "        best_sense = None\n",
    "        for definition, embedding in sense_embeddings.items():\n",
    "            similarity = cosine_similarity([context_embedding], [embedding])[0][0]\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_sense = definition\n",
    "\n",
    "        best_senses[word] = best_sense\n",
    "        best_similarities[word] = max_similarity\n",
    "    \n",
    "    return best_senses, best_similarities\n",
    "\n",
    "# Load data from Excel file\n",
    "file_path = 'execute.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Process each sentence in the 'dummy_text' column\n",
    "word_regex = r'execut\\w*'  # Regex pattern to match all forms of execute\n",
    "\n",
    "results = []\n",
    "similarities = []\n",
    "for sentence in tqdm(df['dummy_text'], desc=\"Processing sentences\"):\n",
    "    # Ensure sentence is a string\n",
    "    sentence = str(sentence)\n",
    "    \n",
    "    # Check for additional words and their meanings in the sentence\n",
    "    additional_words_meanings = {word: additional_dict[word] for word in additional_dict if word in sentence}\n",
    "    \n",
    "    best_senses, best_similarities = disambiguate_word(sentence, word_regex, additional_words_meanings)\n",
    "    \n",
    "    if best_senses:\n",
    "        meanings = [f\"{word}: {sense}\" for word, sense in best_senses.items() if sense]\n",
    "        execute_meaning = \"; \".join(meanings)\n",
    "        max_similarity = max(best_similarities.values())\n",
    "    else:\n",
    "        execute_meaning = \"No sense found\"\n",
    "        max_similarity = None\n",
    "    \n",
    "    results.append(execute_meaning)\n",
    "    similarities.append(max_similarity)\n",
    "\n",
    "# Add the results to the DataFrame\n",
    "df['execute_meaning'] = results\n",
    "df['cosine_similarity'] = similarities\n",
    "\n",
    "# Save the results to a new Excel file\n",
    "output_file_path = 'execute_meaningsAlongWithCosineSimilarity.xlsx'\n",
    "df.to_excel(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
